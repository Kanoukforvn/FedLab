{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import logging\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "cwd = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(cwd, \"../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# configuration\n",
    "from munch import Munch\n",
    "from fedlab.models.mlp import MLP\n",
    "from fedlab.models.build_model import build_model\n",
    "from fedlab.utils.dataset.functional import partition_report\n",
    "from fedlab.utils import Logger, SerializationTool, Aggregators, LogitAdjust, LA_KD, DaAggregator\n",
    "from fedlab.contrib.algorithm.basic_server import SyncServerHandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Munch\n",
    "args.total_client = 10\n",
    "args.alpha = 0.5\n",
    "args.seed = 0\n",
    "args.preprocess = True\n",
    "args.dataname = \"cifar10\"\n",
    "args.model = \"Resnet18\"\n",
    "args.pretrained = 1\n",
    "args.num_users = args.total_client\n",
    "args.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "if args.dataname == \"cifar10\":\n",
    "    args.n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 66\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfedlab\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpartitioned_cifar10\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PartitionedCIFAR10\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m############################################\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#           Set up the dataset             #\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m############################################\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m fed_cifar10 \u001b[38;5;241m=\u001b[39m \u001b[43mPartitionedCIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../datasets/cifar10/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../datasets/cifar10/fedcifar10/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mdataname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mbalance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mpartition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdirichlet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mdir_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Get the dataset for the 0-th client\u001b[39;00m\n\u001b[1;32m     81\u001b[0m dataset_train \u001b[38;5;241m=\u001b[39m fed_cifar10\u001b[38;5;241m.\u001b[39mget_dataset(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/FedLab/fednoro/../fedlab/contrib/dataset/partitioned_cifar10.py:59\u001b[0m, in \u001b[0;36mPartitionedCIFAR10.__init__\u001b[0;34m(self, root, path, dataname, num_clients, num_classes, download, preprocess, balance, partition, unbalance_sgm, num_shards, dir_alpha, verbose, seed, transform, target_transform)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preprocess:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbalance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbalance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43munbalance_sgm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munbalance_sgm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_shards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdir_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdir_alpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FedLab/fednoro/../fedlab/contrib/dataset/partitioned_cifar10.py:117\u001b[0m, in \u001b[0;36mPartitionedCIFAR10.preprocess\u001b[0;34m(self, balance, partition, unbalance_sgm, num_shards, dir_alpha, verbose, seed, download)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets_test \u001b[38;5;241m=\u001b[39m testset\u001b[38;5;241m.\u001b[39mtargets\n\u001b[1;32m    106\u001b[0m partitioner_train \u001b[38;5;241m=\u001b[39m CIFAR10Partitioner(\n\u001b[1;32m    107\u001b[0m     trainset\u001b[38;5;241m.\u001b[39mtargets,\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_clients,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m     seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[1;32m    116\u001b[0m )\n\u001b[0;32m--> 117\u001b[0m partitioner_test \u001b[38;5;241m=\u001b[39m \u001b[43mCIFAR10Partitioner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtestset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_clients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbalance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbalance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43munbalance_sgm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munbalance_sgm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_shards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdir_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdir_alpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_indices_train \u001b[38;5;241m=\u001b[39m partitioner_train\u001b[38;5;241m.\u001b[39mclient_dict\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_indices_test \u001b[38;5;241m=\u001b[39m partitioner_test\u001b[38;5;241m.\u001b[39mclient_dict\n",
      "File \u001b[0;32m~/FedLab/fednoro/../fedlab/utils/dataset/partition.py:135\u001b[0m, in \u001b[0;36mCIFAR10Partitioner.__init__\u001b[0;34m(self, targets, num_clients, balance, partition, unbalance_sgm, num_shards, dir_alpha, verbose, min_require_size, seed)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalance\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m can only be NoneType or bool, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(balance)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# perform partition according to setting\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_partition\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# get sample number count for each client\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient_sample_count \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msamples_num_count(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient_dict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_clients)\n",
      "File \u001b[0;32m~/FedLab/fednoro/../fedlab/utils/dataset/partition.py:165\u001b[0m, in \u001b[0;36mCIFAR10Partitioner._perform_partition\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m         client_dict \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mhomo_partition(client_sample_nums, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples)\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# for dirichlet\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m         client_dict \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_inner_dirichlet_partition\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_clients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdir_alpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mclient_sample_nums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m client_dict\n",
      "File \u001b[0;32m~/FedLab/fednoro/../fedlab/utils/dataset/functional.py:280\u001b[0m, in \u001b[0;36mclient_inner_dirichlet_partition\u001b[0;34m(targets, num_clients, num_classes, dir_alpha, client_sample_nums, verbose)\u001b[0m\n\u001b[1;32m    278\u001b[0m curr_cid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(num_clients)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# If current node is full resample a client\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client_sample_nums[curr_cid] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    282\u001b[0m client_sample_nums[curr_cid] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import logging\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, confusion_matrix\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "cwd = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(cwd, \"../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# configuration\n",
    "from munch import Munch\n",
    "from fedlab.models.mlp import MLP\n",
    "from fedlab.models.build_model import build_model\n",
    "from fedlab.utils.dataset.functional import partition_report\n",
    "from fedlab.utils import Logger, SerializationTool, Aggregators, LogitAdjust, LA_KD, DaAggregator\n",
    "from fedlab.contrib.algorithm.basic_server import SyncServerHandler\n",
    "\n",
    "args = Munch\n",
    "\n",
    "args.total_client = 10\n",
    "args.alpha = 0.5\n",
    "args.seed = 0\n",
    "args.preprocess = True\n",
    "args.dataname = \"cifar10\"\n",
    "args.model = \"Resnet18\"\n",
    "args.pretrained = 1\n",
    "args.num_users = args.total_client\n",
    "#args.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "args.device = \"cuda\"\n",
    "\n",
    "\n",
    "if args.dataname == \"cifar10\":\n",
    "    args.n_classes = 10\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                        format='[%(asctime)s.%(msecs)03d] %(message)s', \n",
    "                        datefmt='%H:%M:%S',\n",
    "                        stream=sys.stdout)\n",
    "\n",
    "logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "\n",
    "# We provide a example usage of patitioned CIFAR10 dataset\n",
    "# Download raw CIFAR10 dataset and partition them according to given configuration\n",
    "\n",
    "from torchvision import transforms\n",
    "from fedlab.contrib.dataset.partitioned_cifar10 import PartitionedCIFAR10\n",
    "\n",
    "############################################\n",
    "#           Set up the dataset             #\n",
    "############################################\n",
    "\n",
    "\n",
    "fed_cifar10 = PartitionedCIFAR10(root=\"../datasets/cifar10/\",\n",
    "                                  path=\"../datasets/cifar10/fedcifar10/\",\n",
    "                                  dataname=args.dataname,\n",
    "                                  num_clients=args.total_client,\n",
    "                                  num_classes=args.n_classes,\n",
    "                                  balance=True,\n",
    "                                  partition=\"dirichlet\",\n",
    "                                  seed=args.seed,\n",
    "                                  dir_alpha=args.alpha,\n",
    "                                  preprocess=args.preprocess,\n",
    "                                  download=True,\n",
    "                                  verbose=True,\n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "# Get the dataset for the 0-th client\n",
    "dataset_train = fed_cifar10.get_dataset(0, type=\"train\")\n",
    "dataset_test = fed_cifar10.get_dataset(0, type=\"test\")\n",
    "\n",
    "# Get the dataloaders\n",
    "dataloader_train = fed_cifar10.get_dataloader(0, batch_size=128, type=\"train\")\n",
    "dataloader_test = fed_cifar10.get_dataloader(0, batch_size=128, type=\"test\")\n",
    "\n",
    "logging.info(\n",
    "    f\"train: {Counter(fed_cifar10.targets_train)}, total: {len(fed_cifar10.targets_train)}\")\n",
    "logging.info(\n",
    "    f\"test: {Counter(fed_cifar10.targets_test)}, total: {len(fed_cifar10.targets_test)}\")\n",
    "\n",
    "\n",
    "############################################\n",
    "#                  Dataset                 #\n",
    "############################################\n",
    "\n",
    "# generate partition report\n",
    "csv_file = \"./partition-reports/cifar10_hetero_dir_0.3_10clients.csv\"\n",
    "partition_report(fed_cifar10.targets_train, fed_cifar10.data_indices_train, \n",
    "                 class_num=args.n_classes, \n",
    "                 verbose=False, file=csv_file)\n",
    "\n",
    "\n",
    "hetero_dir_part_df = pd.read_csv(csv_file,header=0)\n",
    "hetero_dir_part_df = hetero_dir_part_df.set_index('cid')\n",
    "col_names = [f\"class-{i}\" for i in range(args.n_classes)]\n",
    "for col in col_names:\n",
    "    hetero_dir_part_df[col] = (hetero_dir_part_df[col] * hetero_dir_part_df['TotalAmount']).astype(int)\n",
    "\n",
    "#select first 10 clients for bar plot\n",
    "hetero_dir_part_df[col_names].iloc[:10].plot.barh(stacked=True)  \n",
    "plt.tight_layout()\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel('sample num')\n",
    "plt.savefig(f\"./imgs/cifar10_dir_10clients_for_fedavg.png\", dpi=400, bbox_inches = 'tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training on client 3: 100%|██████████| 1/1 [03:50<00:00, 230.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0, Loss 5.4143, Test Accuracy 0.1752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training on client 1:   0%|          | 0/1 [00:48<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 87\u001b[0m\n\u001b[1;32m     84\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m)\n\u001b[1;32m     86\u001b[0m standalone_eval \u001b[38;5;241m=\u001b[39m EvalPipeline(handler\u001b[38;5;241m=\u001b[39mhandler, trainer\u001b[38;5;241m=\u001b[39mtrainer, test_loader\u001b[38;5;241m=\u001b[39mtest_loader)\n\u001b[0;32m---> 87\u001b[0m \u001b[43mstandalone_eval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m standalone_eval\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[2], line 55\u001b[0m, in \u001b[0;36mEvalPipeline.main\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m broadcast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandler\u001b[38;5;241m.\u001b[39mdownlink_package\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# client side\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbroadcast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampled_clients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m uploads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39muplink_package\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# server side\u001b[39;00m\n",
      "File \u001b[0;32m~/FedLab/fednoro/../fedlab/contrib/algorithm/basic_client.py:140\u001b[0m, in \u001b[0;36mSGDSerialClientTrainer.local_process\u001b[0;34m(self, payload, id_list)\u001b[0m\n\u001b[1;32m    138\u001b[0m progress_bar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on client \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mid\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, refresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    139\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mget_dataloader(\u001b[38;5;28mid\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m--> 140\u001b[0m pack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mappend(pack)\n",
      "File \u001b[0;32m~/FedLab/fednoro/../fedlab/contrib/algorithm/basic_client.py:166\u001b[0m, in \u001b[0;36mSGDSerialClientTrainer.train\u001b[0;34m(self, model_parameters, train_loader)\u001b[0m\n\u001b[1;32m    163\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(output, target)\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 166\u001b[0m         \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_parameters]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# client\n",
    "from fedlab.contrib.algorithm.basic_client import SGDSerialClientTrainer, SGDClientTrainer\n",
    "\n",
    "# local train configuration\n",
    "args.epochs = 5\n",
    "args.batch_size = 128\n",
    "args.lr = 0.1\n",
    "\n",
    "trainer = SGDSerialClientTrainer(model, args.total_client, cuda=args.cuda) # serial trainer\n",
    "# trainer = SGDClientTrainer(model, cuda=True) # single trainer\n",
    "\n",
    "trainer.setup_dataset(fed_cifar10)\n",
    "trainer.setup_optim(args.epochs, args.batch_size, args.lr)\n",
    "\n",
    "# server\n",
    "from fedlab.contrib.algorithm.basic_server import SyncServerHandler\n",
    "\n",
    "# global configuration\n",
    "args.com_round = 10\n",
    "args.sample_ratio = 0.1\n",
    "\n",
    "handler = SyncServerHandler(model=model, global_round=args.com_round, sample_ratio=args.sample_ratio, cuda=args.cuda)\n",
    "\n",
    "from fedlab.utils.functional import evaluate\n",
    "from fedlab.core.standalone import StandalonePipeline\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from fedlab.utils.functional import evaluate\n",
    "from fedlab.core.standalone import StandalonePipeline\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "class EvalPipeline(StandalonePipeline):\n",
    "    def __init__(self, handler, trainer, test_loader):\n",
    "        super().__init__(handler, trainer)\n",
    "        self.test_loader = test_loader \n",
    "        self.loss = []\n",
    "        self.acc = []\n",
    "        \n",
    "    def main(self):\n",
    "        t=0\n",
    "        while self.handler.if_stop is False:\n",
    "            # server side\n",
    "            sampled_clients = self.handler.sample_clients()\n",
    "            broadcast = self.handler.downlink_package\n",
    "            \n",
    "            # client side\n",
    "            self.trainer.local_process(broadcast, sampled_clients)\n",
    "            uploads = self.trainer.uplink_package\n",
    "\n",
    "            # server side\n",
    "            for pack in uploads:\n",
    "                self.handler.load(pack)\n",
    "\n",
    "            loss, acc = evaluate(self.handler.model, nn.CrossEntropyLoss(), self.test_loader)\n",
    "            print(\"Round {}, Loss {:.4f}, Test Accuracy {:.4f}\".format(t, loss, acc))\n",
    "            t+=1\n",
    "            self.loss.append(loss)\n",
    "            self.acc.append(acc)\n",
    "    \n",
    "    def show(self):\n",
    "        plt.figure(figsize=(8,4.5))\n",
    "        ax = plt.subplot(1,2,1)\n",
    "        ax.plot(np.arange(len(self.loss)), self.loss)\n",
    "        ax.set_xlabel(\"Communication Round\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        \n",
    "        ax2 = plt.subplot(1,2,2)\n",
    "        ax2.plot(np.arange(len(self.acc)), self.acc)\n",
    "        ax2.set_xlabel(\"Communication Round\")\n",
    "        ax2.set_ylabel(\"Accuarcy\")\n",
    "        \n",
    "        \n",
    "test_data = torchvision.datasets.CIFAR10(root=\"../datasets/cifar10/\",\n",
    "                                       train=False,\n",
    "                                       transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(test_data, batch_size=1024)\n",
    "\n",
    "standalone_eval = EvalPipeline(handler=handler, trainer=trainer, test_loader=test_loader)\n",
    "standalone_eval.main()\n",
    "\n",
    "standalone_eval.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
